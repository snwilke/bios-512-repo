{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f2fcd9-2cc5-4e31-8aa2-b47106d273ce",
   "metadata": {},
   "source": [
    "# Homework 09\n",
    "This homework is based on the classification and regression lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a600f-4693-4efc-8b3b-fa033a140406",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 1\n",
    "#### In the table below, fill in the definition column with a short (no more than two sentence) definition for each vocab word. If it can be summarized by a formula, give the formula. \n",
    "\n",
    "| Vocab Word | Definition |\n",
    "|:--------|:--------|\n",
    "| **One-hot coding** | **Encode a categorical variable as binary indicator columns with exactly one “1” per row and the rest “0”.** |\n",
    "| **Feature selection*** | **Choose a subset of features that best predict the target to reduce variance and improve interpretability. Methods include filter, wrapper, and embedded.** |\n",
    "| **Classifier** | **A model that maps features to discrete class labels, often also producing class probabilities.** |\n",
    "| **Precision** | **Fraction of predicted positives that are true positives.** |\n",
    "| **Recall** | **Fraction of actual positives that are correctly identified.** |\n",
    "| **F1 Score** | **Harmonic mean of precision and recall.** |\n",
    "| **Parsimonious model** | **The simplest model that achieves adequate predictive performance, using minimal parameters or features.** |\n",
    "| **Ridge regression** | **Linear regression with an L2 penalty that shrinks coefficients.** |\n",
    "| **LASSO regression** | **Linear regression with an L1 penalty that drives some coefficients to zero.** |\n",
    "| **Cross validation** | **Estimate out-of-sample performance by splitting data into K folds, training on K−1 folds, and validating on the held-out fold, then averaging.** |\n",
    "| **Tree based methods** | **Models that partition the feature space using hierarchical splits (decision trees) and ensembles like random forests and gradient boosting.** |\n",
    "\n",
    "*Just give the general idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d3f305-b18b-4a5d-81b8-0db018c3c9d3",
   "metadata": {},
   "source": [
    "## Question 2 \n",
    "#### a) What shape does a perfect classifier look like on an ROC curve? What about a bad classifier?\n",
    "#### b) Think about the formula for an F1 score. What does it mean when the F1 score is close to 1? Close to 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2058e2-3829-4bbb-a9f5-cee73a53f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A) A perfect classifier’s ROC curve goes straight up the left axis to (0,1) then across the top—area under the curve (AUC) = 1.\n",
    "## A bad classifier lies along the diagonal from (0,0) to (1,1) with AUC ≈ 0.5, showing random guessing.\n",
    "## B) F1 = 1 means both precision and recall are high—predictions are accurate and comprehensive.\n",
    "## F1 ≈ 0 means poor performance—either many false positives or many missed positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914fb5f4-f116-410c-8f38-c66f9eeaee3e",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### Compare the following aspects of linear vs. logistic regression.\n",
    "|  | Linear | Logistic |\n",
    "|:--------|:--------|:--------|\n",
    "| **Chart Shape** | **straight line** | **sigmoid** |\n",
    "| **Dependent Variable Type** | **Continuous.** | **Binary categorical {0,1}** |\n",
    "| **Purpose** (regression or classification) | **regression** | **classification** |\n",
    "| **Range of output variable** ($y_i$ or $p_i$) | **(−∞,∞)** | **(0,1) (then class via threshold).** |\n",
    "| **Method*** | **Ordinary least squares (minimize MSE).** | **Maximum likelihood estimation (Bernoulli/logistic loss).** |\n",
    "| **Example of use** | **Predict house price.** | **Predict churn yes/no.** |  \n",
    "  \n",
    "*Meaning ordinary least squares or maximum likelihood estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fbebda-5655-48b1-a2ea-8668e5aa9efe",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Why is it important to train then test our model? How do we do that? (2-3 sentences. Not looking for code, just general explanation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b730bc-5fb2-484d-af9a-d3d6a9f071f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We train on one subset and test on a separate unseen subset to estimate generalization and detect overfitting.\n",
    "## Split the data into train and test. Fit and tune on the train only (often with k‑fold cross‑validation), then compute final metrics once on the untouched test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f265f3-45c5-4efb-8dc5-0cc7c3e8beec",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "This question runs through a linear regression example. We want to predict median house value based on the other variables.\n",
    "#### a) First, load the `housing.csv` data set. Look at the data in some useful way. Why is linear regression appropriate here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff032c62-b1b3-4462-aa0f-67b87144ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear regression is appropriate because the target (median_house_value) is continuous. As a baseline, OLS is reasonable after scaling numeric features and dummy‑coding categoricals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee3e1ca3-c7aa-472c-80ff-03caef6d435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(file, \"rt\"):\n",
      "“cannot open file '/mnt/data/housing.csv': No such file or directory”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
      "1. read.csv(\"/mnt/data/housing.csv\", stringsAsFactors = FALSE)",
      "2. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
      "3. file(file, \"rt\")"
     ]
    }
   ],
   "source": [
    "set.seed(123)\n",
    "df <- read.csv(\"/mnt/data/housing.csv\", stringsAsFactors = FALSE)\n",
    "stopifnot(\"median_house_value\" %in% names(df))\n",
    "str(df)\n",
    "summary(df$median_house_value)\n",
    "df <- df[complete.cases(df), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a566f-615e-48df-9bad-a89c1b2d0426",
   "metadata": {},
   "source": [
    "#### b) Scale data and split it 75/25 training/testing. Set seed = 123."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d17ab5-2740-4856-b4b4-c5f65965cb28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in sample.int(n, floor(0.75 * n)): length(n) == 1L is not TRUE\n",
     "output_type": "error",
     "traceback": [
      "Error in sample.int(n, floor(0.75 * n)): length(n) == 1L is not TRUE\nTraceback:\n",
      "1. sample.int(n, floor(0.75 * n))",
      "2. stopifnot(length(n) == 1L)"
     ]
    }
   ],
   "source": [
    "n <- nrow(df)\n",
    "idx_tr <- sample.int(n, floor(0.75 * n))\n",
    "train <- df[idx_tr, ]\n",
    "test  <- df[-idx_tr, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439535fe-8224-42d6-9464-ecc6ddc15a44",
   "metadata": {},
   "source": [
    "#### c) Fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45245e-3ce0-4e07-9b21-0c46e6a3835b",
   "metadata": {},
   "source": [
    "#### d) Make predictions on test data and show them in an actual vs. predicted plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52c9ed-31cd-43a6-8e49-91aaee62d650",
   "metadata": {},
   "source": [
    "#### e) Make a residuals plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a045c2-cfef-4338-8a5f-11ede6d20dcb",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "This question runs through a logistic regression example. We want to predict diabetes diagnosis based on the other variables. \n",
    "#### a) First, load the `diabetes.csv` data set. Look at the data in some useful way. Why is logistic regression appropriate here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3844183-23e8-4a49-99b2-25b3b3191e1f",
   "metadata": {},
   "source": [
    "#### b) Scale data and split it 75/25 training/testing. Set seed = 123."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea27f31-acf0-4913-8bef-5e1e6248503e",
   "metadata": {},
   "source": [
    "#### c) Fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c2181-60f9-4e62-8579-39dc5763f03a",
   "metadata": {},
   "source": [
    "#### d) Make predictions on test data. Print a table with the number of true positives, false positives, true negatives, false negatives, and accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f4d86c-8836-4b34-968d-6e062ddf7562",
   "metadata": {},
   "source": [
    "#### e) Fit a LASSO-regularized logistic regression model. Again, set seed = 123. Which variables are the most important (which ones don't go to zero)? How does the LASSO model affect the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455dd7a9-6502-4261-a8e7-00474fc7b3ef",
   "metadata": {},
   "source": [
    "#### f) Make a plot of actual vs. predicted values for the LASSO model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
